{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction and General Information\n",
    "\n",
    "* We are using Naive Bayes Classification technique to classify the handwritten digits in MNIST database. \n",
    "\n",
    "* Naive Bayes Classifier is a probabilistic machine learning model. It works on the principle of Bayes Theorem.\n",
    "    \n",
    "* Bayes Theorem states that P(y|X) = (P(X|y) * P(y)) / P(X). Here y is the class label (digit 0 or 1), X represents the image features.\n",
    "\n",
    "* Using this theorem, we can find the class probability of the data for given set of features. It is assumed at all features are independent of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "* For the purpose of this project, we are considering only a subset of MNIST dataset. We filter the training and testing sets to obtain the images of digits 0 and 1 only.\n",
    "\n",
    "* The main objective of this project is to apply the concept of Naive Bayes Classification technique on the subset of MNIST dataset and evaulate the performance of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Used\n",
    "(Data Source: http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "* We are using MNIST dataset containing images of handwritten digits from 0 - 9. \n",
    "\n",
    "* Each image is of size 28 pixels x 28 pixels, making 784 pixels in total. This dataset is divided into training and testing sets. The training set consists of 60,000 images and testing set consists of 10,000 images. \n",
    "\n",
    "* We build the model based on the training dataset and use testing dataset to evaluate the performance of the classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach and Methodology\n",
    "\n",
    "* Loading and Filtering MNIST Dataset to obtain the images of digits 0 and 1.\n",
    "\n",
    "* Convert the given dataset in 3D Numpy format to 2D pandas dataframe. Now each row is representing a single image in pandas dataframe.\n",
    "\n",
    "* Each image consists of two features namely, average brightness and standard deviation. Perform feature extraction for each image from train and test datasets of digits 0 and 1.\n",
    "\n",
    "* Compute density parameters - Mean and Variance for each of the extracted features. \n",
    "\n",
    "* Apply Naive Baye's classifier technique to classify the image as 0 or 1 on the test dataset by using the density parameters computed above. \n",
    "\n",
    "* Evaluate the performance of the classifier by computing the accuracy of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import math\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from math import pi\n",
    "from math import exp\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading and Filtering MNIST Dataset\n",
    "\n",
    "* Download the data from the source link given above and define the paths to access the data.\n",
    "* Filter the desired digit (0 or 1) from the dataset.\n",
    "* The dataset is available in 3D Numpy format. So convert it to 2D pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = str(pathlib.Path().absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGE_PATH = BASE_PATH + '/mnist_dataset/train_digit_images_dataset'\n",
    "TRAIN_LABEL_PATH = BASE_PATH + '/mnist_dataset/train_digit_labels_dataset'\n",
    "TEST_IMAGE_PATH = BASE_PATH + '/mnist_dataset/test_digit_images_dataset'\n",
    "TEST_LABEL_PATH = BASE_PATH + '/mnist_dataset/test_digit_labels_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Method to download the MNIST data and extract the data for particular digit from the entire data:\n",
    "* This method takes the desired digit to be extracted and the data paths as parameters.\n",
    "* After extracted the image data of a particular digit from the entire dataset, We convert it into pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_mnist_dataset_to_dataframe(digit, digit_image_path, digit_label_path):\n",
    "    mnist_data_image, mnist_data_label = loadlocal_mnist(digit_image_path, digit_label_path)\n",
    "    \n",
    "    indices_of_desired_digit = np.where((mnist_data_label == digit))\n",
    "    filtered_image_data = mnist_data_image[indices_of_desired_digit]\n",
    "    \n",
    "    filtered_image_data_df = pd.DataFrame(data=filtered_image_data, index=None, columns=None)\n",
    "\n",
    "    return filtered_image_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of digit 0 train dataset: 5923\n",
      "Size of digit 0 test dataset: 980\n"
     ]
    }
   ],
   "source": [
    "train_0_df = converting_mnist_dataset_to_dataframe(0, TRAIN_IMAGE_PATH, TRAIN_LABEL_PATH)\n",
    "test_0_df = converting_mnist_dataset_to_dataframe(0, TEST_IMAGE_PATH, TEST_LABEL_PATH)\n",
    "print(\"Size of digit 0 train dataset: {}\".format(train_0_df.shape[0]))\n",
    "print(\"Size of digit 0 test dataset: {}\".format(test_0_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of digit 1 train dataset: 6742\n",
      "Size of digit 1 test dataset: 1135\n"
     ]
    }
   ],
   "source": [
    "train_1_df = converting_mnist_dataset_to_dataframe(1, TRAIN_IMAGE_PATH, TRAIN_LABEL_PATH)\n",
    "test_1_df = converting_mnist_dataset_to_dataframe(1, TEST_IMAGE_PATH, TEST_LABEL_PATH)\n",
    "print(\"Size of digit 1 train dataset: {}\".format(train_1_df.shape[0]))\n",
    "print(\"Size of digit 1 test dataset: {}\".format(test_1_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Extraction\n",
    "\n",
    "* Each row of the pandas dataframe represents an image. Each image consists of following two features - Average Brightness and Standard Deviation.\n",
    "* Average Brightness is extracted by computing the mean of all pixel values in a row.\n",
    "* Standard Deviation is extracted by computing standard deviation of all the pixel values in a row.\n",
    "* Extract these features of digit 0 and 1 seperately and then combine them in a single dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Method to extract features from the dataframe:\n",
    "\n",
    "* We perform feature extraction seperately on train_0, train_1, test_0 and test_1 dataframes.\n",
    "* This methods takes a dataframe and the desired digit as parameters. \n",
    "* Average Brightness and Standard Deviation is computed for each image i.e. each row of the input dataframe.\n",
    "* A column for class vector is also added to the extracted features dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(df, digit):\n",
    "    avg_brightness = df.agg('mean', axis = 'columns')\n",
    "    avg_std = df.agg('std', axis = 'columns')\n",
    "    extracted_features_df = pd.concat([avg_brightness, avg_std], axis=1)\n",
    "    extracted_features_df.columns = ['averageBrightness', 'standardDeviation']\n",
    "    extracted_features_df['classVector'] = digit\n",
    "    \n",
    "    return extracted_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of digit 0 extracted features dataframe: 5923\n"
     ]
    }
   ],
   "source": [
    "train_0_extracted_features_df = feature_extraction(train_0_df, 0)\n",
    "print(\"Size of digit 0 extracted features from train dataframe: {}\".format(train_0_extracted_features_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   averageBrightness  standardDeviation  classVector\n",
      "0             39.662             83.941            0\n",
      "1             45.195             89.087            0\n",
      "2             46.565             91.800            0\n",
      "3             47.533             91.750            0\n",
      "4             58.091             99.273            0\n"
     ]
    }
   ],
   "source": [
    "print(train_0_extracted_features_df.round(3).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      averageBrightness  standardDeviation  classVector\n",
      "5918             36.849             83.442            0\n",
      "5919             30.084             73.061            0\n",
      "5920             39.562             83.475            0\n",
      "5921             45.062             88.404            0\n",
      "5922             44.422             88.973            0\n"
     ]
    }
   ],
   "source": [
    "print(train_0_extracted_features_df.round(3).tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of digit 1 extracted features from train dataframe: 6742\n"
     ]
    }
   ],
   "source": [
    "train_1_extracted_features_df = feature_extraction(train_1_df, 1)\n",
    "print(\"Size of digit 1 extracted features from train dataframe: {}\".format(train_1_extracted_features_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   averageBrightness  standardDeviation  classVector\n",
      "0             21.856             66.121            1\n",
      "1             22.508             67.885            1\n",
      "2             13.870             52.649            1\n",
      "3             14.824             54.617            1\n",
      "4             21.144             64.798            1\n"
     ]
    }
   ],
   "source": [
    "print(train_1_extracted_features_df.round(3).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      averageBrightness  standardDeviation  classVector\n",
      "6737             15.491             55.311            1\n",
      "6738             20.932             64.326            1\n",
      "6739             15.911             55.794            1\n",
      "6740             19.302             61.458            1\n",
      "6741             12.279             47.491            1\n"
     ]
    }
   ],
   "source": [
    "print(train_1_extracted_features_df.round(3).tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of digit 0 extracted features from test dataframe: 980\n"
     ]
    }
   ],
   "source": [
    "test_0_extracted_features_df = feature_extraction(test_0_df, 0)\n",
    "print(\"Size of digit 0 extracted features from test dataframe: {}\".format(test_0_extracted_features_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   averageBrightness  standardDeviation  classVector\n",
      "0             47.212             92.463            0\n",
      "1             37.960             81.688            0\n",
      "2             37.509             81.939            0\n",
      "3             67.417            105.710            0\n",
      "4             43.903             88.954            0\n"
     ]
    }
   ],
   "source": [
    "print(test_0_extracted_features_df.round(3).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     averageBrightness  standardDeviation  classVector\n",
      "975             49.635             92.342            0\n",
      "976             42.518             84.580            0\n",
      "977             36.282             80.183            0\n",
      "978             56.047             98.186            0\n",
      "979             69.921            107.090            0\n"
     ]
    }
   ],
   "source": [
    "print(test_0_extracted_features_df.round(3).tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of digit 1 extracted features from test dataframe: 1135\n"
     ]
    }
   ],
   "source": [
    "test_1_extracted_features_df = feature_extraction(test_1_df, 1)\n",
    "print(\"Size of digit 1 extracted features from test dataframe: {}\".format(test_1_extracted_features_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   averageBrightness  standardDeviation  classVector\n",
      "0             12.591             48.898            1\n",
      "1             17.672             59.554            1\n",
      "2             20.662             66.499            1\n",
      "3             16.311             57.236            1\n",
      "4             13.804             52.370            1\n"
     ]
    }
   ],
   "source": [
    "print(test_1_extracted_features_df.round(3).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      averageBrightness  standardDeviation  classVector\n",
      "1130             18.744             60.695            1\n",
      "1131             17.869             58.316            1\n",
      "1132             21.606             65.197            1\n",
      "1133             22.036             67.327            1\n",
      "1134             21.989             66.490            1\n"
     ]
    }
   ],
   "source": [
    "print(test_1_extracted_features_df.round(3).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Method to combine extracted features of digits 0 and 1 into a single dataframe:\n",
    "\n",
    "* This method combines the extracted features of digit 0 and 1 from the training set into single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_train_features_df():    \n",
    "    combined_train_features_df = pd.concat([train_0_extracted_features_df, train_1_extracted_features_df])\n",
    "    \n",
    "    return combined_train_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of combined train dataset: 12665\n"
     ]
    }
   ],
   "source": [
    "combined_train_features_df = create_combined_train_features_df()\n",
    "print(\"Size of combined train dataset: {}\".format(combined_train_features_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   averageBrightness  standardDeviation  classVector\n",
      "0             39.662             83.941            0\n",
      "1             45.195             89.087            0\n",
      "2             46.565             91.800            0\n",
      "3             47.533             91.750            0\n",
      "4             58.091             99.273            0\n"
     ]
    }
   ],
   "source": [
    "print(combined_train_features_df.round(3).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      averageBrightness  standardDeviation  classVector\n",
      "6737             15.491             55.311            1\n",
      "6738             20.932             64.326            1\n",
      "6739             15.911             55.794            1\n",
      "6740             19.302             61.458            1\n",
      "6741             12.279             47.491            1\n"
     ]
    }
   ],
   "source": [
    "print(combined_train_features_df.round(3).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Density Estimation\n",
    "\n",
    "* We assume that both the features extracted above are independent of each other and each of the image follows normal distribution.\n",
    "* Normal Distribution is characterized by Mean and Variance.\n",
    "* We compute Mean and Variance for both the features from the combined dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Method to compute Mean and Variance for each feature:\n",
    "\n",
    "* This method takes a dataframe as parameter.\n",
    "* It groups the data in the dataframe by class vector and computes Mean and Variance for each column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_distribution_parameters(df):\n",
    "    return df.groupby('classVector').agg(['mean','var']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">averageBrightness</th>\n",
       "      <th colspan=\"2\" halign=\"left\">standardDeviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classVector</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.22</td>\n",
       "      <td>115.29</td>\n",
       "      <td>87.49</td>\n",
       "      <td>101.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.38</td>\n",
       "      <td>31.45</td>\n",
       "      <td>61.41</td>\n",
       "      <td>82.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            averageBrightness         standardDeviation        \n",
       "                         mean     var              mean     var\n",
       "classVector                                                    \n",
       "0                       44.22  115.29             87.49  101.63\n",
       "1                       19.38   31.45             61.41   82.81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "statistics = normal_distribution_parameters(combined_train_features_df)\n",
    "display(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Implementing Naive Bayes Classifier\n",
    "\n",
    "* This will predict the class vector of the previously unknown dataset i.e. test dataset. \n",
    "\n",
    "* Extracted features of the test dataset will be used here.\n",
    "\n",
    "* Each row of the extracted features dataframe contains Average Brightness and Standard Deviation values of a single image.\n",
    "\n",
    "* We find the class probabilities of the image.\n",
    "    * Let D = data representing Average Brightness and Standard Deviation of a particular image.\n",
    "    * Compute P(class = 0 | D)\n",
    "    * Compute P(class = 1 | D)\n",
    "    \n",
    "* Compare the values of P(class = 0 | D) and P(class = 1 | D). Highest among the two is considered as the class label for that particular image, D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula for computing class probabilities:\n",
    "\n",
    "* P(class = 0 | D) = P(D | class = 0) * P(class = 0)\n",
    "              = P(averageBrightness | class = 0) * P(standardDeviation | class = 0) * P(class = 0)\n",
    "\n",
    "* P(class = 1 | D) = P(D | class = 1) * P(class = 1)\n",
    "              = P(averageBrightness | class = 1) * P(standardDeviation | class = 1) * P(class = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Formula for computing probability of continuous feature attributes:\n",
    "\n",
    "* P(x | class) can be computed by the gaussian formula shown below.\n",
    "    * x is averageBrightness or standardDeviation\n",
    "    * class is 0 or 1"
   ]
  },
  {
   "attachments": {
    "61463c3decedda46e356782e24051ec7dd3c34c8.svg": {
     "image/svg+xml": [
      "<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="35.682ex" height="7.509ex" style="vertical-align: -3.171ex;" viewBox="0 -1867.7 15363.2 3233.2" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">{\displaystyle g(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}\exp {\left(-{\frac {1}{2}}{\frac {(x-\mu )^{2}}{\sigma ^{2}}}\right)}.}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3C3" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3C0" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path>
<path stroke-width="1" id="E1-MJMAIN-221A" d="M95 178Q89 178 81 186T72 200T103 230T169 280T207 309Q209 311 212 311H213Q219 311 227 294T281 177Q300 134 312 108L397 -77Q398 -77 501 136T707 565T814 786Q820 800 834 800Q841 800 846 794T853 782V776L620 293L385 -193Q381 -200 366 -200Q357 -200 354 -197Q352 -195 256 15L160 225L144 214Q129 202 113 190T95 178Z"></path>
<path stroke-width="1" id="E1-MJMAIN-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path>
<path stroke-width="1" id="E1-MJMAIN-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path>
<path stroke-width="1" id="E1-MJMAIN-70" d="M36 -148H50Q89 -148 97 -134V-126Q97 -119 97 -107T97 -77T98 -38T98 6T98 55T98 106Q98 140 98 177T98 243T98 296T97 335T97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 61 434T98 436Q115 437 135 438T165 441T176 442H179V416L180 390L188 397Q247 441 326 441Q407 441 464 377T522 216Q522 115 457 52T310 -11Q242 -11 190 33L182 40V-45V-101Q182 -128 184 -134T195 -145Q216 -148 244 -148H260V-194H252L228 -193Q205 -192 178 -192T140 -191Q37 -191 28 -194H20V-148H36ZM424 218Q424 292 390 347T305 402Q234 402 182 337V98Q222 26 294 26Q345 26 384 80T424 218Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3BC" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path>
<path stroke-width="1" id="E1-MJSZ4-28" d="M758 -1237T758 -1240T752 -1249H736Q718 -1249 717 -1248Q711 -1245 672 -1199Q237 -706 237 251T672 1700Q697 1730 716 1749Q718 1750 735 1750H752Q758 1744 758 1741Q758 1737 740 1713T689 1644T619 1537T540 1380T463 1176Q348 802 348 251Q348 -242 441 -599T744 -1218Q758 -1237 758 -1240Z"></path>
<path stroke-width="1" id="E1-MJSZ4-29" d="M33 1741Q33 1750 51 1750H60H65Q73 1750 81 1743T119 1700Q554 1207 554 251Q554 -707 119 -1199Q76 -1250 66 -1250Q65 -1250 62 -1250T56 -1249Q55 -1249 53 -1249T49 -1250Q33 -1250 33 -1239Q33 -1236 50 -1214T98 -1150T163 -1052T238 -910T311 -727Q443 -335 443 251Q443 402 436 532T405 831T339 1142T224 1438T50 1716Q33 1737 33 1741Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-67" x="0" y="0"></use>
 <use xlink:href="#E1-MJMAIN-28" x="480" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="870" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="1442" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="2109" y="0"></use>
<g transform="translate(3166,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="2600" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="1049" y="676"></use>
<g transform="translate(60,-915)">
 <use xlink:href="#E1-MJMATHI-3C3" x="0" y="0"></use>
<g transform="translate(572,0)">
 <use xlink:href="#E1-MJMAIN-221A" x="0" y="33"></use>
<rect stroke="none" width="1074" height="60" x="833" y="774"></rect>
<g transform="translate(833,0)">
 <use xlink:href="#E1-MJMAIN-32" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-3C0" x="500" y="0"></use>
</g>
</g>
</g>
</g>
</g>
<g transform="translate(6172,0)">
 <use xlink:href="#E1-MJMAIN-65"></use>
 <use xlink:href="#E1-MJMAIN-78" x="444" y="0"></use>
 <use xlink:href="#E1-MJMAIN-70" x="973" y="0"></use>
</g>
<g transform="translate(7868,0)">
 <use xlink:href="#E1-MJSZ4-28"></use>
<g transform="translate(792,0)">
 <use xlink:href="#E1-MJMAIN-2212" x="0" y="0"></use>
<g transform="translate(778,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="620" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="60" y="676"></use>
 <use xlink:href="#E1-MJMAIN-32" x="60" y="-687"></use>
</g>
</g>
<g transform="translate(1639,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="3751" height="60" x="0" y="220"></rect>
<g transform="translate(60,770)">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-78" x="389" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2212" x="1184" y="0"></use>
 <use xlink:href="#E1-MJMATHI-3BC" x="2184" y="0"></use>
<g transform="translate(2788,0)">
 <use xlink:href="#E1-MJMAIN-29" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="550" y="513"></use>
</g>
</g>
<g transform="translate(1362,-780)">
 <use xlink:href="#E1-MJMATHI-3C3" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="810" y="408"></use>
</g>
</g>
</g>
</g>
 <use xlink:href="#E1-MJSZ4-29" x="6423" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2E" x="15084" y="0"></use>
</g>
</svg>"
     ]
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![61463c3decedda46e356782e24051ec7dd3c34c8.svg](attachment:61463c3decedda46e356782e24051ec7dd3c34c8.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, \n",
    "* ðœ‡ - mean of the distribution\n",
    "* ðœŽ - standard deviation of the distribution\n",
    "* ðœŽ^2 - variance of the distribution\n",
    "* x = averageBrightness or standardDeviation of the image.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Method to calculate Gaussian probability distribution for Average Brightness and Standard Deviation of each row of the combined features dataframe:\n",
    "\n",
    "* This method takes the feature value (can be either of Average Brightness and Standard Deviation), mean and standard deviation of the feature distribution as parameters.\n",
    "* This method is used for computation of -\n",
    "    * P(averageBrightness | class = 0)\n",
    "    * P(standardDeviation | class = 0)\n",
    "    * P(averageBrightness | class = 1)\n",
    "    * P(standardDeviation | class = 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gaussian_probability(feature_val, mean, stdev):\n",
    "    exponent = exp(-((feature_val-mean)**2 / (2 * stdev**2 )))\n",
    "    return (1 / (sqrt(2 * pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Method to compute class probabilities for each row of the combined features dataframe:\n",
    "\n",
    "* Each row of the combined features dataframe represents an image. \n",
    "* This method is used to compute P(class = 0 | D) and P(class = 1 | D); D = data representing Average Brightness and Standard Deviation of a particular image.\n",
    "* Probabilities obtained using above formula are stored in a dictionary of form {0: probability value, 1: probability value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_class_probability(row):\n",
    "#     combined_train_features_df = create_combined_train_features_df()\n",
    "    total_images = combined_train_features_df.shape[0]\n",
    "    features = ['averageBrightness', 'standardDeviation']\n",
    "    classVector = [0,1]\n",
    "    class_probabilities = dict()\n",
    "    stats = combined_train_features_df.groupby('classVector').agg(['mean','std'])\n",
    "\n",
    "    for class_value in classVector:\n",
    "        class_probabilities[class_value] = (combined_train_features_df.classVector == class_value).sum()/total_images\n",
    "        for i in range(len(features)):\n",
    "            feature_df = stats[features[i]]\n",
    "            feature_mean = feature_df.loc[class_value]['mean']\n",
    "            feature_std = feature_df.loc[class_value]['std']\n",
    "            class_probabilities[class_value] *= calc_gaussian_probability(row[i], feature_mean, feature_std)\n",
    "            \n",
    "    return class_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Method to predict the class for a given previously unknown dataset:\n",
    "\n",
    "* We now have class probabilities in the form of dictionary for a particular image.\n",
    "* In this method, we will compare the probabilites of the image belonging to class = 0 and class = 1. The highest of the two becomes our predicted class label for the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class_for_dataset(row):\n",
    "    class_probabilities = calc_class_probability(row)\n",
    "    predicted_label, highest_prob = None, -1\n",
    "    \n",
    "    for class_val, probability in class_probabilities.items():\n",
    "        if predicted_label is None or probability > highest_prob:\n",
    "            highest_prob = probability\n",
    "            predicted_label = class_val\n",
    "            \n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Method to build Naive Baye's classifier model:\n",
    "\n",
    "* This method takes a dataframe as parameter. \n",
    "* We use the extracted features of digit 0 and 1 from test dataset for building this classification model.\n",
    "* Iterate through the dataframe and convert each row to a list. Store all such lists in rows_list.\n",
    "* Now iterate through this list consisting of all the rows for predicting their class.\n",
    "* Store the predictions for all these rows of the dataframe in a form of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(test_df):\n",
    "    class_predictions = []\n",
    "    rows_list = []\n",
    "\n",
    "    for index, rows in test_df.iterrows():\n",
    "        test_row =[rows.averageBrightness, rows.standardDeviation]\n",
    "        rows_list.append(test_row)\n",
    "\n",
    "    for row in rows_list:\n",
    "        predicted_class = predict_class_for_dataset(row)\n",
    "        class_predictions.append(predicted_class)\n",
    "\n",
    "    return class_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluating Classifier Model Performance\n",
    "\n",
    "* In order to evaluate the model performance, we will compute the accuracy of the class predictions made by the model. \n",
    "\n",
    "* Accuracy for predicting digits 0 and 1 is computed seperately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Method to calculate accuracy of the naive bayes classifier model:\n",
    "\n",
    "* In this method, model prediction for digit 0 and 1 are compared with the ground truth respectively.\n",
    "* Number of correct predictions is counted against the total number of data in test dataset of a particular digit.\n",
    "* Accuracy is given by (Number of correct predictions / Total number of observations) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(digit, test_df):\n",
    "    class_count = test_df.shape[0]\n",
    "    actual = [digit]*class_count\n",
    "    predicted = naive_bayes_classifier(test_df)\n",
    "    correctly_predicted = 0\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correctly_predicted += 1\n",
    "\n",
    "    accuracy = round(correctly_predicted/len(actual) * 100,2)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for digit 0: 91.43 %\n",
      "Accuracy for digit 1: 92.42 %\n"
     ]
    }
   ],
   "source": [
    "prediction_accuracy_0 = calc_accuracy(0,test0_extracted_features_df)\n",
    "prediction_accuracy_1 = calc_accuracy(1,test1_extracted_features_df)\n",
    "\n",
    "print(\"Accuracy for digit 0: {} %\".format(prediction_accuracy_0))\n",
    "print(\"Accuracy for digit 1: {} %\".format(prediction_accuracy_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Conclusion\n",
    "\n",
    "* We built a Naive Baye's Classification Model to classify the digits as 0 and 1 from the subset of MNIST testing dataset.\n",
    "* This model is able to classify digit 0 with 91.4 % accuracy and digit 1 with 92.4 % accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
